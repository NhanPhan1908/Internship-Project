import sys
import cv2
import requests
from PyQt6.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit, QGroupBox, QTabWidget
from PyQt6.QtCore import Qt, QTimer
from PyQt6.QtGui import QPixmap, QImage

BACKEND_URL = "http://127.0.0.1:8000/recognize/" 

class FaceRecognitionTab(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.capture = None
        self.timer = None
    
    def initUI(self):
        self.setWindowTitle("Nh·∫≠n di·ªán khu√¥n m·∫∑t")
        self.setGeometry(100, 100, 900, 600)

        # Camera Viewfinder Group
        camera_group = QGroupBox("Camera Feed")
        self.camera_viewfinder = QLabel("Camera Feed")
        self.camera_viewfinder.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.camera_viewfinder.setFixedSize(480, 360)
        self.camera_viewfinder.setStyleSheet("border: 1px solid black; background-color: lightgray")

        # Recognition Result Group
        recognition_group = QGroupBox("K·∫øt qu·∫£ nh·∫≠n di·ªán")
        self.recognition_label = QLabel("Recognition Result")
        self.recognition_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.recognition_label.setFixedSize(480, 360)
        self.recognition_label.setStyleSheet("border: 1px solid black; background-color: lightgray")

        # Detect Result Group
        detect_group = QGroupBox("Detect Result")
        self.detect_label = QLabel("Detect Result")
        self.detect_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.detect_label.setFixedSize(480, 360)
        self.detect_label.setStyleSheet("border: 1px solid black; background-color: lightgray")

        # Employee Data Group
        employee_group = QGroupBox("Employee Data")
        self.employee_data_label = QLabel("Employee Data")
        self.employee_data_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.employee_data_label.setFixedSize(480, 360)
        self.employee_data_label.setStyleSheet("border: 1px solid black; background-color: lightgray")

        # Layout cho Camera Feed, Recognition, Detect v√† Employee Data (2x2)
        grid_layout = QVBoxLayout()
        
        top_row_layout = QHBoxLayout()
        top_row_layout.addWidget(camera_group)
        top_row_layout.addWidget(recognition_group)

        bottom_row_layout = QHBoxLayout()
        bottom_row_layout.addWidget(detect_group)
        bottom_row_layout.addWidget(employee_group)

        grid_layout.addLayout(top_row_layout)
        grid_layout.addLayout(bottom_row_layout)

        # Button Group (Ch·ª©c nƒÉng)
        button_group = QGroupBox("Ch·ª©c nƒÉng")
        self.start_camera_button = QPushButton("B·∫≠t Camera")
        self.start_camera_button.clicked.connect(self.start_camera)
        self.capture_button = QPushButton("Ch·ª•p & Nh·∫≠n di·ªán")
        self.capture_button.clicked.connect(self.capture_and_recognize_face)
        self.capture_button.setEnabled(False)

        button_layout = QVBoxLayout()
        button_layout.addWidget(self.start_camera_button)
        button_layout.addWidget(self.capture_button)
        button_group.setLayout(button_layout)

        # Log Output Group
        log_group = QGroupBox("Ph·∫£n h·ªìi h·ªá th·ªëng")
        self.log_output = QTextEdit()
        self.log_output.setReadOnly(True)
        self.log_output.setFixedHeight(120)
        log_layout = QVBoxLayout()
        log_layout.addWidget(self.log_output)
        log_group.setLayout(log_layout)

        # Layout T·ªïng
        main_layout = QHBoxLayout()
        
        # Ph·∫ßn camera v√† nh·∫≠n di·ªán chi·∫øm 2/3 di·ªán t√≠ch
        main_layout.addLayout(grid_layout, 3)
        
        # Ph·∫ßn ch·ª©c nƒÉng chi·∫øm 1/3 di·ªán t√≠ch
        right_layout = QVBoxLayout()
        right_layout.setContentsMargins(0, 0, 0, 0)
        right_layout.setSpacing(0)

        right_layout.addWidget(button_group)
        right_layout.addWidget(log_group)
        
        main_layout.addLayout(right_layout, 1)

        self.setLayout(main_layout)

    def start_camera(self):
        if self.capture is not None:
            self.log_output.append("‚ö†Ô∏è Camera ƒë√£ ƒë∆∞·ª£c b·∫≠t r·ªìi!")
            return

        self.capture = cv2.VideoCapture(0)
        
        if not self.capture.isOpened():
            self.log_output.append("‚ùå Kh√¥ng th·ªÉ m·ªü camera. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")
            self.capture = None
            return
        
        self.log_output.append("üì∑ Camera ƒë√£ m·ªü th√†nh c√¥ng.")
        self.capture_button.setEnabled(True)

        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)

    def update_frame(self):
        if self.capture is None:
            return

        ret, frame = self.capture.read()
        if ret:
            self.display_image(frame, self.camera_viewfinder)
        else:
            self.log_output.append("‚ùå L·ªói khi ƒë·ªçc d·ªØ li·ªáu t·ª´ camera.")

    def capture_and_recognize_face(self):
        self.log_output.append("üîÑ ƒêang g·ª≠i ·∫£nh ƒë·∫øn backend...")

        if self.capture is None:
            self.log_output.append("‚ùå Camera ch∆∞a ƒë∆∞·ª£c m·ªü.")
            return

        ret, frame = self.capture.read()
        if not ret:
            self.log_output.append("‚ùå Kh√¥ng th·ªÉ ch·ª•p ·∫£nh t·ª´ camera.")
            return

        _, img_encoded = cv2.imencode(".jpg", frame)
        files = {"file": ("face.jpg", img_encoded.tobytes(), "image/jpeg")}

        try:
            response = requests.post("http://localhost:8000/recognize/", files=files)
            if response.status_code == 200:
                result = response.json()
                self.log_output.append(f"‚úÖ {result['message']}")
            else:
                self.log_output.append(f"‚ùå L·ªói t·ª´ server: {response.status_code}")
        except Exception as e:
            self.log_output.append(f"‚ùå L·ªói k·∫øt n·ªëi: {str(e)}")
    
    def display_image(self, img, label):
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        height, width, channel = img_rgb.shape
        bytes_per_line = 3 * width
        qt_img = QPixmap.fromImage(QImage(img_rgb.data, width, height, bytes_per_line, QImage.Format.Format_RGB888))
        label.setPixmap(qt_img.scaled(label.width(), label.height(), Qt.AspectRatioMode.KeepAspectRatio))

    def closeEvent(self, event):
        if self.capture:
            self.capture.release()

class MainApp(QTabWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t")
        self.setGeometry(100, 100, 1400, 800)
        self.initUI()
    
    def initUI(self):
        self.face_recognition_tab = FaceRecognitionTab()
        self.addTab(self.face_recognition_tab, "Nh·∫≠n di·ªán khu√¥n m·∫∑t")

if __name__ == "__main__":
    app = QApplication(sys.argv)
    main_app = MainApp()
    main_app.show()
    sys.exit(app.exec())
