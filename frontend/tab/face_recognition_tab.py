import sys
import cv2
import requests
from PyQt6.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit, QGroupBox, QTabWidget
from PyQt6.QtCore import Qt, QTimer, QTime
from PyQt6.QtGui import QPixmap, QImage

BACKEND_URL = "http://127.0.0.1:8000/recognize/" 

class FaceRecognitionTab(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.capture = None
        self.prev_face = None
        self.stable_start_time = None
        self.stability_duration = 2000
        self.timer = None
    
    def initUI(self):
        self.setWindowTitle("Nháº­n diá»‡n khuÃ´n máº·t")
        self.setGeometry(100, 100, 900, 600)
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        
        # Camera Viewfinder Group
        camera_group = QGroupBox("Camera Feed")
        self.camera_viewfinder = QLabel("Camera Feed")
        self.camera_viewfinder.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.camera_viewfinder.setFixedSize(480, 360)
        self.camera_viewfinder.setStyleSheet("border: 1px solid black; background-color: lightgray")
        camera_layout = QVBoxLayout()
        camera_layout.addWidget(self.camera_viewfinder)
        camera_group.setLayout(camera_layout)
        # Recognition Result Group
        recognition_group = QGroupBox("Káº¿t quáº£ nháº­n diá»‡n")
        self.recognition_label = QLabel("Recognition Result")
        self.recognition_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.recognition_label.setFixedSize(480, 360)
        self.recognition_label.setStyleSheet("border: 1px solid black; background-color: lightgray")
        recognition_layout = QVBoxLayout()
        recognition_layout.addWidget(self.recognition_label)
        recognition_group.setLayout(recognition_layout)
        
        # Detect Result Group
        detect_group = QGroupBox("Detect Result")
        self.detect_label = QLabel("Detect Result")
        self.detect_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.detect_label.setFixedSize(480, 360)
        self.detect_label.setStyleSheet("border: 1px solid black; background-color: lightgray")
        detect_layout = QVBoxLayout()
        detect_layout.addWidget(self.detect_label)
        detect_group.setLayout(detect_layout)
        
        # Employee Data Group
        employee_group = QGroupBox("Employee Data")
        self.employee_data_label = QLabel("Employee Data")
        self.employee_data_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.employee_data_label.setFixedSize(480, 360)
        self.employee_data_label.setStyleSheet("border: 1px solid black; background-color: lightgray")
        employee_layout = QVBoxLayout()
        employee_layout.addWidget(self.employee_data_label)
        employee_group.setLayout(employee_layout)
        
        # Layout cho Camera Feed, Recognition, Detect vÃ  Employee Data (2x2)
        grid_layout = QVBoxLayout()
        
        top_row_layout = QHBoxLayout()
        top_row_layout.addWidget(camera_group)
        top_row_layout.addWidget(recognition_group)

        bottom_row_layout = QHBoxLayout()
        bottom_row_layout.addWidget(detect_group)
        bottom_row_layout.addWidget(employee_group)

        grid_layout.addLayout(top_row_layout)
        grid_layout.addLayout(bottom_row_layout)

        # Button Group (Chá»©c nÄƒng)
        button_group = QGroupBox("Chá»©c nÄƒng")
        self.start_camera_button = QPushButton("Báº­t Camera")
        self.start_camera_button.clicked.connect(self.start_camera)
        self.capture_button = QPushButton("Chá»¥p & Nháº­n diá»‡n")
        self.capture_button.clicked.connect(self.capture_and_recognize_face)
        self.capture_button.setEnabled(False)
        
        
        button_layout = QVBoxLayout()
        button_layout.addWidget(self.start_camera_button)
        button_layout.addWidget(self.capture_button)
        button_group.setLayout(button_layout)

        # Log Output Group
        log_group = QGroupBox("Pháº£n há»“i há»‡ thá»‘ng")
        self.log_output = QTextEdit()
        self.log_output.setReadOnly(True)
        self.log_output.setFixedHeight(120)
        log_layout = QVBoxLayout()
        log_layout.addWidget(self.log_output)
        log_group.setLayout(log_layout)
        
        
        # Layout Tá»•ng
        main_layout = QHBoxLayout()
        
        # Pháº§n camera vÃ  nháº­n diá»‡n chiáº¿m 2/3 diá»‡n tÃ­ch
        main_layout.addLayout(grid_layout, 3)
        
        # Pháº§n chá»©c nÄƒng chiáº¿m 1/3 diá»‡n tÃ­ch
        right_layout = QVBoxLayout()
        right_layout.setContentsMargins(0, 0, 0, 0)
        right_layout.setSpacing(0)

        right_layout.addWidget(button_group)
        right_layout.addWidget(log_group)
        
        main_layout.addLayout(right_layout, 1)

        self.setLayout(main_layout)
    
    def showEvent(self, event):
        super().showEvent(event)
        if self.capture is None:
            self.log_output.append("Äang má»Ÿ camera...")
            self.start_camera()
        else:
            self.log_output.append("Camera Ä‘Ã£ má»Ÿ.")
    def hideEvent(self, a0):
        self.stop_camera()
        return super().hideEvent(a0)
    
    def start_camera(self):
        if self.capture is not None:
            self.log_output.append("Camera Ä‘Ã£ Ä‘Æ°á»£c báº­t rá»“i!")
            return

        self.capture = cv2.VideoCapture(1)
        
        if not self.capture.isOpened():
            self.log_output.append("âŒ KhÃ´ng thá»ƒ má»Ÿ camera. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i.")
            self.capture = None
            return
        
        self.log_output.append("ğŸ“· Camera Ä‘Ã£ má»Ÿ thÃ nh cÃ´ng.")
        self.capture_button.setEnabled(True)

        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)

    def update_frame(self):
        if self.capture is None:
            return

        ret, frame = self.capture.read()
        if not ret:
            self.log_output.append("âŒ Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« camera.")
            return

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

        if len(faces) > 0:
            (x, y, w, h) = faces[0]  #láº¥y khuÃ´n máº·t Ä‘áº§u tiÃªn Ä‘Æ°á»£c cho vÃ o camera
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2) # bonding box

        # HÃ m kiá»ƒm tra Ä‘á»™ á»•n Ä‘á»‹nh, nháº­n 4 giÃ¡ trá»‹ prev_face, so sÃ¡nh náº¿u khÃ´ng thay Ä‘á»•i nhiá»u <10 thÃ¬ coi nhÆ° giá»¯ nguyÃªn vá»‹ trÃ­
            if self.prev_face is not None:
                 dx = abs(x - self.prev_face[0])
                 dy = abs(y - self.prev_face[1])
                 dw = abs(w - self.prev_face[2])
                 dh = abs(h - self.prev_face[3])

                 if dx < 40 and dy < 40 and dw < 40 and dh < 40:
                    if self.stable_start_time is None:
                         self.stable_start_time = QTime.currentTime()
                    else:
                         elapsed = self.stable_start_time.msecsTo(QTime.currentTime())
                         if elapsed > self.stability_duration:
                            self.log_output.append("âœ… GÆ°Æ¡ng máº·t á»•n Ä‘á»‹nh - tiáº¿n hÃ nh chá»¥p...")
                            self.capture_and_recognize_face()
                            self.stable_start_time = None  # Reset sau khi chá»¥p
                 else:
                    self.stable_start_time = None  # Di chuyá»ƒn â†’ reset thá»i gian
            else:
                self.stable_start_time = QTime.currentTime()
            self.prev_face = (x, y, w, h)
        else:
            self.prev_face = None
            self.stable_start_time = None
        self.display_image(frame, self.camera_viewfinder)

    def capture_and_recognize_face(self):
        self.log_output.append("ğŸ”„ Äang gá»­i áº£nh Ä‘áº¿n backend...")

        if self.capture is None:
            self.log_output.append("âŒ Camera chÆ°a Ä‘Æ°á»£c má»Ÿ.")
            return

        ret, frame = self.capture.read()
        if not ret:
            self.log_output.append("âŒ KhÃ´ng thá»ƒ chá»¥p áº£nh tá»« camera.")
            return
       
        _, img_encoded = cv2.imencode(".jpg", frame)
        files = {"file": ("face.jpg", img_encoded.tobytes(), "image/jpeg")}

        try:
            response = requests.post("http://localhost:8000/recognize/", files=files)
            if response.status_code == 200:
                result = response.json()
                status = result.get("status", "unknown")
                detect = result.get("detect", False)
                recognize = result.get("recognize", False)
                name = result.get("name", "KhÃ´ng rÃµ")
                confidence = result.get("confidence", "N/A")
                message = result.get("message", "")

                self.log_output.append("ğŸ“¸ Káº¿t quáº£ nháº­n diá»‡n:")
                self.log_output.append(f"ğŸ”¹ Tráº¡ng thÃ¡i: {status}")
                self.log_output.append(f"ğŸ”¹ KhuÃ´n máº·t phÃ¡t hiá»‡n: {'âœ… CÃ³' if detect else 'âŒ KhÃ´ng'}")
                self.log_output.append(f"ğŸ”¹ Nháº­n diá»‡n thÃ nh cÃ´ng: {'âœ… CÃ³' if recognize else 'âŒ KhÃ´ng'}")
                self.log_output.append(f"ğŸ”¹ TÃªn: {name}")
                self.log_output.append(f"ğŸ”¹ Äá»™ tá»± tin: {confidence}")
                self.log_output.append(f"ğŸ’¬ ThÃ´ng bÃ¡o: {message}")
            else:
                self.log_output.append(f"âŒ Lá»—i tá»« server: {response.status_code}")
        except Exception as e:
            self.log_output.append(f"âŒ Lá»—i káº¿t  ngoÃ i: {repr(e)}")
    
    
    def stop_camera(self):
        if self.capture:
            self.capture.release()
            self.capture = None
            self.log_output.append("âŒ Camera Ä‘Ã£ táº¯t.")
        if self.timer:
            self.timer.stop()
            self.timer = None
    
    def display_image(self, img, label):
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        height, width, channel = img_rgb.shape
        bytes_per_line = 3 * width
        qt_img = QPixmap.fromImage(QImage(img_rgb.data, width, height, bytes_per_line, QImage.Format.Format_RGB888))
        label.setPixmap(qt_img.scaled(label.width(), label.height(), Qt.AspectRatioMode.KeepAspectRatio))

    def closeEvent(self, event):
        if self.capture:
            self.capture.release()

class MainApp(QTabWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t")
        self.setGeometry(100, 100, 1400, 800)
        self.initUI()
    
    def initUI(self):
        self.face_recognition_tab = FaceRecognitionTab()
        self.addTab(self.face_recognition_tab, "Nháº­n diá»‡n khuÃ´n máº·t")

if __name__ == "__main__":
    app = QApplication(sys.argv)
    main_app = MainApp()
    main_app.show()
    sys.exit(app.exec())
