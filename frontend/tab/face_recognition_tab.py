import sys
import cv2
import requests
from PyQt6.QtWidgets import (
    QApplication, QWidget, QLabel, QVBoxLayout, QHBoxLayout,
    QPushButton, QTextEdit, QGroupBox, QTabWidget
)
from PyQt6.QtCore import Qt, QTimer, QTime
from PyQt6.QtGui import QPixmap, QImage
from PyQt6.QtWidgets import QLayout
from .camera_thread import CameraThread
from .face_recognition_thread import RecognitionThread

BACKEND_URL = "http://127.0.0.1:8000/recognize/"

class FaceRecognitionTab(QWidget):
    def __init__(self):
        super().__init__()
        self.capture_thread = None  #thread cá»§a Camera
        self.capture = None # biáº¿n chá»¥p áº£nh
        self.last_frame = None #biáº¿n luu frame cuá»‘i cÃ¹ng, gá»­i vá» back end
        self.prev_face = None  # biáº¿n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh gÆ°Æ¡ng máº·t Ä‘Ã£ á»•n Ä‘á»‹nh chÆ°a
        self.loading_recog = None # Biáº¿n Ä‘á»ƒ loading giá»¯a cÃ¡c láº§n recog
        self.stable_start_time = None # biáº¿n Ä‘á»ƒ lÆ°u thá»i gian chá»¥p áº£nh
        self.stability_duration = 2000  # Äá»™ á»•n Ä‘á»‹nh gÆ°Æ¡ng máº·t 2s
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') #

        self.initUI()
        
    # UI     
    def initUI(self):
        self.setWindowTitle("Nháº­n diá»‡n khuÃ´n máº·t")
        self.setGeometry(100, 100, 900, 600)

        # UI components
        self.camera_viewfinder = self.create_display_label("Camera Feed")
        self.recognition_label = self.create_display_label("Recognition Result")
        self.detect_label = self.create_display_label("Detect Result")
        self.employee_data_label = self.create_display_label("Employee Data")
        self.log_output = QTextEdit()
        self.log_output.setReadOnly(True)
        self.log_output.setFixedHeight(120)

        # Buttons
        self.start_camera_button = QPushButton("Báº­t Camera")
        self.start_camera_button.clicked.connect(self.start_camera)

        self.capture_button = QPushButton("Chá»¥p & Nháº­n diá»‡n")
        self.capture_button.clicked.connect(self.capture_and_recognize_face)
        self.capture_button.setEnabled(False)

        # Layouts chÃ­nh
        grid_layout = QVBoxLayout()
        top_row = QHBoxLayout() 
        bottom_row = QHBoxLayout()
        # Báº£ng hiá»ƒn thá»‹ gá»“m CAmera, áº¢nh tráº£ vá» khi nháº­n diá»‡n, káº¿t quáº£ detect cÃ³ bouding box vÃ  áº¢nh nhÃ¢n viÃªn trong db
        top_row.addWidget(self.wrap_group("Camera Feed", self.camera_viewfinder))
        top_row.addWidget(self.wrap_group("Káº¿t quáº£ nháº­n diá»‡n", self.recognition_label))
        bottom_row.addWidget(self.wrap_group("Detect Result", self.detect_label))
        bottom_row.addWidget(self.wrap_group("Employee Data", self.employee_data_label))
        grid_layout.addLayout(top_row)
        grid_layout.addLayout(bottom_row)
        
        # layout cho cÃ¡c nÃºt chá»©c  (Ä‘Ã£ bá»‹ vÃ´ hiá»‡u hÃ³a do thÃªm automatic function)
        button_layout = QVBoxLayout()
        button_layout.addWidget(self.start_camera_button) # nÃºt start camera
        button_layout.addWidget(self.capture_button) #nÃºt chá»¥p áº£nh
        
        # layout cho button vÃ  log, náº±m bÃªn pháº£i mÃ n hÃ¬nh
        right_layout = QVBoxLayout()
        right_layout.addWidget(self.wrap_group("Chá»©c nÄƒng", button_layout))
        right_layout.addWidget(self.wrap_group("Pháº£n há»“i há»‡ thá»‘ng", self.log_output))
        
        #PhÃ¢n chia tá»‰ lá»‡ giá»¯a cÃ¡c lay out, BÃªn trÃ¡i chiáº¿m tá»‰ lá»‡ lá»›n hÆ¡n bÃªn pháº£i
        main_layout = QHBoxLayout()
        main_layout.addLayout(grid_layout, 3)
        main_layout.addLayout(right_layout, 1)

        self.setLayout(main_layout)

    def create_display_label(self, text):
        label = QLabel(text)
        label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        label.setFixedSize(480, 360)
        label.setStyleSheet("border: 1px solid black; background-color: lightgray")
        return label

    def wrap_group(self, title, content):
        group = QGroupBox(title)
        layout = QVBoxLayout()
        if isinstance(content, QLayout):
            layout.addLayout(content)
        else:
            layout.addWidget(content)
        group.setLayout(layout)
        return group

    def showEvent(self, event):
        super().showEvent(event)
        self.log_output.append("Äang má»Ÿ camera...")
        self.start_camera() # tá»± Ä‘á»™ng má»Ÿ camera khi vÃ o tab
        
    # má»Ÿ camera    
    def start_camera(self):
        if self.capture_thread and self.capture_thread.isRunning():
            self.log_output.append("ğŸ“· Camera Ä‘Ã£ báº­t.")
            return

        self.capture_thread = CameraThread() # sá»­ dá»¥ng Thread cho camera trong camera_thread.py
        self.capture = self.capture_thread.capture
        self.capture_thread.frame_ready.connect(self.update_frame) #gá»­i frame
        self.capture_thread.running = True
        self.capture_thread.start()
        self.capture_button.setEnabled(True)
        self.log_output.append("âœ… Camera khá»Ÿi Ä‘á»™ng thÃ nh cÃ´ng.")
        
    #dá»«ng camera
    def stop_camera(self):
        if self.capture_thread and self.capture_thread.isRunning():
            self.capture_thread.stop()
            self.capture_thread = None
            self.log_output.append("ğŸ›‘ Camera Ä‘Ã£ dá»«ng.")
            
    #khi out tab hoáº·c chuyá»ƒn tab, dá»«ng camera
    def closeEvent(self, event):
        self.stop_camera()
        event.accept()
        
    #Frame Ä‘Æ°á»£c cáº­p nháº­t liÃªn tá»¥c
    def update_frame(self, frame):
        if frame is None:
            return

        self.last_frame = frame.copy()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #
        faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)
        
        #boundingbox
        if len(faces) > 0:
            (x, y, w, h) = faces[0]
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            if self.prev_face:
                dx, dy, dw, dh = [abs(a - b) for a, b in zip((x, y, w, h), self.prev_face)]
                if dx < 40 and dy < 40 and dw < 40 and dh < 40: #giá»¯ cho gÆ°Æ¡ng máº·t cá»‘ Ä‘á»‹nh, náº¿u dx dy dw dh chÃªnh lá»‡ch khÃ´ng quÃ¡ 40, tá»± Ä‘á»™ng chá»¥p áº£nh
                    if not self.stable_start_time:
                        self.stable_start_time = QTime.currentTime()
                    else:
                        elapsed = self.stable_start_time.msecsTo(QTime.currentTime())
                        if elapsed > self.stability_duration:
                            self.log_output.append("âœ… GÆ°Æ¡ng máº·t á»•n Ä‘á»‹nh - tiáº¿n hÃ nh chá»¥p...")
                            self.capture_and_recognize_face() #chá»¥p áº£nh
                            self.stable_start_time = None #táº¯t stable cam
                else:
                    self.stable_start_time = None
            else:
                self.stable_start_time = QTime.currentTime()
            self.prev_face = (x, y, w, h)
        else:
            self.prev_face = None
            self.stable_start_time = None

        self.display_image(frame, self.camera_viewfinder)
        
    def delay_recog(self):
        QTimer.singleShot(15000, self.open_recog) #khoan, chá» khoáº£ng chá»«ng lÃ  15s
        
    def open_recog(self):
        self.loading_recog= False # ok tiáº¿p tá»¥c Ä‘i
    
    def capture_and_recognize_face(self):
        if self.capture is None:
            self.log_output.append("âŒ Camera chÆ°a Ä‘Æ°á»£c má»Ÿ.")
            return
        if self.last_frame is None:
            self.log_output.append("âŒ KhÃ´ng cÃ³ áº£nh Ä‘á»ƒ nháº­n diá»‡n.")
            return

        ret, frame = self.capture.read()
        if not ret:
            self.log_output.append("âŒ KhÃ´ng thá»ƒ chá»¥p áº£nh tá»« camera.")
            return
        
        if self.loading_recog:
            self.log_output.append("Chá» má»™t chÃºt")
            return
        
        self.loading_recog = True

        self.log_output.append("ğŸ”„ Äang gá»­i áº£nh Ä‘áº¿n backend...")
        
        self.recognition_thread = RecognitionThread(self.last_frame.copy())
        self.recognition_thread.result_ready.connect(self.display_recognition_result)
        self.recognition_thread.error.connect(lambda msg: self.log_output.append(f"âŒ {msg}"))
        self.recognition_thread.finished.connect(self.open_recog)
        self.recognition_thread.start()

    def display_recognition_result(self, result):
        self.log_output.append("ğŸ“¸ Káº¿t quáº£ nháº­n diá»‡n:")
        self.log_output.append(f"ğŸ”¹ Tráº¡ng thÃ¡i: {result.get('status', 'unknown')}")
        self.log_output.append(f"ğŸ”¹ PhÃ¡t hiá»‡n: {'âœ… CÃ³' if result.get('detect') else 'âŒ KhÃ´ng'}")
        self.log_output.append(f"ğŸ”¹ Nháº­n diá»‡n: {'âœ… CÃ³' if result.get('recognize') else 'âŒ KhÃ´ng'}")
        self.log_output.append(f"ğŸ”¹ TÃªn: {result.get('name', 'KhÃ´ng rÃµ')}")
        self.log_output.append(f"ğŸ”¹ Employee_id: {result.get('employee_id', 'N/A')}")
        self.log_output.append(f"ğŸ”¹ Äá»™ tá»± tin: {result.get('confidence', 'N/A')}")
        self.log_output.append(f"ğŸ’¬ {result.get('message', '')}")

    def display_image(self, img, label):
        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        height, width, channel = rgb_image.shape
        bytes_per_line = 3 * width
        qt_image = QImage(rgb_image.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        label.setPixmap(QPixmap.fromImage(qt_image).scaled(label.width(), label.height(), Qt.AspectRatioMode.KeepAspectRatio))
